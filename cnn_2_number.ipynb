{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cnn_2_number.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNUTVpPonJJn/tVhh54vjAW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sogangori/choongang20/blob/master/cnn_2_number.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GwB_XHDH1_Gw",
        "colab_type": "text"
      },
      "source": [
        "2 자리수 숫자 CNN 분류기 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ClP9Ucwu2BPH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import load_digits"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W5nLNSOT2Iol",
        "colab_type": "code",
        "outputId": "8143f6fd-2c0a-4190-9966-5b5585d60e9a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "x, y = load_digits(return_X_y=True)\n",
        "x.shape, y.shape, set(y)"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((1797, 64), (1797,), {0, 1, 2, 3, 4, 5, 6, 7, 8, 9})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_8u_yK6Y4WKp",
        "colab_type": "text"
      },
      "source": [
        "공유 : http://bitly.kr/1CC8BWNm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ucqLIsAHfGEy",
        "colab_type": "text"
      },
      "source": [
        "학습데이터와 테스트 데이터를 나눕니다"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dmiRMc44dpfa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "36b3cdbb-6d96-47ce-c038-1ff037b26c84"
      },
      "source": [
        "m = len(y)//2\n",
        "x_train = x[:m]\n",
        "y_train = y[:m]\n",
        "x_test = x[m:m*2]\n",
        "y_test = y[m:m*2]\n",
        "x_train = np.reshape(x_train, [-1, 8, 8])\n",
        "x_test = np.reshape(x_test, [-1, 8, 8])\n",
        "x_train.shape"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(898, 8, 8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g5Jh-Eb1dwQB",
        "colab_type": "text"
      },
      "source": [
        "이미지를 2개씩 좌우로 붙여서 합성데이터를 만듭니다\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rMTjpasteKRb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "85cb6f17-6265-4922-99aa-6157fcf95e4a"
      },
      "source": [
        "x_train_l, x_train_r = np.split(x_train, 2, axis=0) # 데이터를 반 나눕니다\n",
        "x_train_lr = np.concatenate((x_train_l, x_train_r), axis=2) # 두 데이터를 좌우로 붙입니다\n",
        "x_test_l, x_test_r = np.split(x_test, 2, axis=0) \n",
        "x_test_lr = np.concatenate((x_test_l, x_test_r), axis=2)\n",
        "y_train_l, y_train_r = np.split(y_train, 2, axis=0) \n",
        "y_train = np.stack((y_train_l, y_train_r), -1)\n",
        "y_test_l, y_test_r = np.split(y_test, 2, axis=0) \n",
        "y_test = np.stack((y_test_l, y_test_r), -1)\n",
        "x_train_lr.shape, x_test_lr.shape, y_train.shape, y_test.shape"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((449, 8, 16), (449, 8, 16), (449, 2), (449, 2))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qUKdrSy746j6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MyModel(keras.Model): # github.com/sogangori/choongang20/ \n",
        "  def __init__(self):    \n",
        "    super(MyModel, self).__init__()\n",
        "    self.k = 10 # 클래스 갯수 \n",
        "    self.seq = 2 # 자릿수\n",
        "    self.opt = tf.optimizers.SGD(learning_rate=0.01)#Stochatic Gradient Descent 확률적 경사 하강\n",
        "    self.conv0 = keras.layers.Conv2D(16, [3,3], padding='same', activation=keras.activations.relu)\n",
        "    self.conv1 = keras.layers.Conv2D(32, [3,3], padding='same', activation=keras.activations.relu)\n",
        "    self.pool0 = keras.layers.MaxPool2D([2,2], padding='same')\n",
        "    self.pool1 = keras.layers.MaxPool2D([2,2], padding='same')\n",
        "    self.flatten = keras.layers.Flatten()\n",
        "    self.dense = keras.layers.Dense(units=self.k * self.seq)\n",
        "  \n",
        "  def call(self, x):\n",
        "    #x (1797, 64)\n",
        "    x_4d = tf.reshape(x, [-1,8,8*2,1]) \n",
        "    x_4d = tf.cast(x_4d, tf.float32)\n",
        "    net = self.conv0(x_4d)\n",
        "    net = self.pool0(net)\n",
        "    net = self.conv1(net)\n",
        "    net = self.pool1(net)\n",
        "    net = self.flatten(net)    \n",
        "    h = self.dense(net)\n",
        "    h = tf.reshape(h, [-1, self.seq, self.k]) # 2:두자리수, 10:10개의 클래스 \n",
        "    h = tf.nn.softmax(h, axis=2)\n",
        "    return h\n",
        "\n",
        "  def get_loss(self, y, h):\n",
        "    #학습할때 nan이 발생하는 경우 값을 clip(자르다) (최소값, 최대값) \n",
        "    h = tf.clip_by_value(h, 1e-8, 1 - 1e-8) # h 가 0이나 1이 되지 않도록 하는 안전장치 \n",
        "    cross_entropy = - (y * tf.math.log(h) + (1 - y) * tf.math.log(1 - h)) \n",
        "    loss = tf.reduce_mean(cross_entropy)\n",
        "    return loss\n",
        "\n",
        "  def get_accuracy(self, y, h):    \n",
        "    predict = tf.argmax(h, -1)\n",
        "    is_equal = tf.equal(y, predict)\n",
        "    self.acc = tf.reduce_mean(tf.cast(is_equal, tf.float32)) # True > 1, False > 0 로 cast\n",
        "    self.acc_all = tf.reduce_mean(tf.cast(tf.reduce_all(is_equal, axis=1), tf.float32))\n",
        "\n",
        "  def fit(self, x, y, epoch=1):\n",
        "    # x : (m, 8, 16), y: (m, 2)    \n",
        "    y_hot = tf.one_hot(y, depth=self.k, axis=-1)#(m, 2, 10)  \n",
        "    for i in range(epoch):\n",
        "      with tf.GradientTape() as tape: #경사 기록 장치\n",
        "        h = self.call(x)\n",
        "        loss = self.get_loss(y_hot, h)        \n",
        "      grads = tape.gradient(loss, self.trainable_variables) #경사 계산\n",
        "      self.opt.apply_gradients(zip(grads, self.trainable_variables)) # 가중치에서 경사를 빼기\n",
        "      self.get_accuracy(y, h)\n",
        "      if i%10==0:\n",
        "        print('%d/%d loss:%.3f acc:%.3f acc_all:%.3f'%(i, epoch, loss, self.acc, self.acc_all))\n",
        "model = MyModel()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hExFpO6F2hmG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "968187c9-9e37-4adf-9904-d4111ffa4293"
      },
      "source": [
        "model.fit(x_train_lr, y_train, epoch=5000) #학습 "
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0/5000 loss:0.296 acc:0.290 acc_all:0.100\n",
            "10/5000 loss:0.296 acc:0.291 acc_all:0.102\n",
            "20/5000 loss:0.295 acc:0.291 acc_all:0.102\n",
            "30/5000 loss:0.295 acc:0.292 acc_all:0.102\n",
            "40/5000 loss:0.295 acc:0.294 acc_all:0.105\n",
            "50/5000 loss:0.295 acc:0.294 acc_all:0.105\n",
            "60/5000 loss:0.295 acc:0.295 acc_all:0.105\n",
            "70/5000 loss:0.295 acc:0.296 acc_all:0.105\n",
            "80/5000 loss:0.294 acc:0.296 acc_all:0.105\n",
            "90/5000 loss:0.294 acc:0.297 acc_all:0.107\n",
            "100/5000 loss:0.294 acc:0.297 acc_all:0.107\n",
            "110/5000 loss:0.294 acc:0.298 acc_all:0.107\n",
            "120/5000 loss:0.294 acc:0.298 acc_all:0.107\n",
            "130/5000 loss:0.294 acc:0.298 acc_all:0.107\n",
            "140/5000 loss:0.294 acc:0.301 acc_all:0.107\n",
            "150/5000 loss:0.293 acc:0.300 acc_all:0.107\n",
            "160/5000 loss:0.293 acc:0.302 acc_all:0.111\n",
            "170/5000 loss:0.293 acc:0.303 acc_all:0.111\n",
            "180/5000 loss:0.293 acc:0.303 acc_all:0.111\n",
            "190/5000 loss:0.293 acc:0.303 acc_all:0.111\n",
            "200/5000 loss:0.293 acc:0.303 acc_all:0.111\n",
            "210/5000 loss:0.292 acc:0.305 acc_all:0.111\n",
            "220/5000 loss:0.292 acc:0.306 acc_all:0.111\n",
            "230/5000 loss:0.292 acc:0.306 acc_all:0.111\n",
            "240/5000 loss:0.292 acc:0.305 acc_all:0.111\n",
            "250/5000 loss:0.292 acc:0.304 acc_all:0.109\n",
            "260/5000 loss:0.292 acc:0.304 acc_all:0.109\n",
            "270/5000 loss:0.291 acc:0.305 acc_all:0.109\n",
            "280/5000 loss:0.291 acc:0.307 acc_all:0.114\n",
            "290/5000 loss:0.291 acc:0.306 acc_all:0.111\n",
            "300/5000 loss:0.291 acc:0.307 acc_all:0.111\n",
            "310/5000 loss:0.291 acc:0.310 acc_all:0.111\n",
            "320/5000 loss:0.291 acc:0.310 acc_all:0.111\n",
            "330/5000 loss:0.291 acc:0.311 acc_all:0.111\n",
            "340/5000 loss:0.290 acc:0.312 acc_all:0.114\n",
            "350/5000 loss:0.290 acc:0.315 acc_all:0.114\n",
            "360/5000 loss:0.290 acc:0.315 acc_all:0.114\n",
            "370/5000 loss:0.290 acc:0.315 acc_all:0.114\n",
            "380/5000 loss:0.290 acc:0.316 acc_all:0.114\n",
            "390/5000 loss:0.290 acc:0.316 acc_all:0.114\n",
            "400/5000 loss:0.289 acc:0.320 acc_all:0.114\n",
            "410/5000 loss:0.289 acc:0.320 acc_all:0.114\n",
            "420/5000 loss:0.289 acc:0.322 acc_all:0.114\n",
            "430/5000 loss:0.289 acc:0.323 acc_all:0.114\n",
            "440/5000 loss:0.289 acc:0.324 acc_all:0.116\n",
            "450/5000 loss:0.289 acc:0.323 acc_all:0.114\n",
            "460/5000 loss:0.288 acc:0.325 acc_all:0.116\n",
            "470/5000 loss:0.288 acc:0.325 acc_all:0.116\n",
            "480/5000 loss:0.288 acc:0.326 acc_all:0.116\n",
            "490/5000 loss:0.288 acc:0.329 acc_all:0.118\n",
            "500/5000 loss:0.288 acc:0.332 acc_all:0.122\n",
            "510/5000 loss:0.288 acc:0.331 acc_all:0.122\n",
            "520/5000 loss:0.288 acc:0.330 acc_all:0.120\n",
            "530/5000 loss:0.287 acc:0.331 acc_all:0.120\n",
            "540/5000 loss:0.287 acc:0.331 acc_all:0.120\n",
            "550/5000 loss:0.287 acc:0.333 acc_all:0.120\n",
            "560/5000 loss:0.287 acc:0.334 acc_all:0.120\n",
            "570/5000 loss:0.287 acc:0.335 acc_all:0.122\n",
            "580/5000 loss:0.287 acc:0.336 acc_all:0.125\n",
            "590/5000 loss:0.286 acc:0.336 acc_all:0.125\n",
            "600/5000 loss:0.286 acc:0.335 acc_all:0.122\n",
            "610/5000 loss:0.286 acc:0.336 acc_all:0.125\n",
            "620/5000 loss:0.286 acc:0.337 acc_all:0.125\n",
            "630/5000 loss:0.286 acc:0.339 acc_all:0.127\n",
            "640/5000 loss:0.286 acc:0.340 acc_all:0.127\n",
            "650/5000 loss:0.285 acc:0.340 acc_all:0.127\n",
            "660/5000 loss:0.285 acc:0.341 acc_all:0.129\n",
            "670/5000 loss:0.285 acc:0.343 acc_all:0.131\n",
            "680/5000 loss:0.285 acc:0.345 acc_all:0.134\n",
            "690/5000 loss:0.285 acc:0.346 acc_all:0.134\n",
            "700/5000 loss:0.285 acc:0.345 acc_all:0.134\n",
            "710/5000 loss:0.285 acc:0.344 acc_all:0.131\n",
            "720/5000 loss:0.284 acc:0.343 acc_all:0.131\n",
            "730/5000 loss:0.284 acc:0.343 acc_all:0.131\n",
            "740/5000 loss:0.284 acc:0.344 acc_all:0.131\n",
            "750/5000 loss:0.284 acc:0.344 acc_all:0.131\n",
            "760/5000 loss:0.284 acc:0.344 acc_all:0.131\n",
            "770/5000 loss:0.284 acc:0.345 acc_all:0.134\n",
            "780/5000 loss:0.283 acc:0.345 acc_all:0.134\n",
            "790/5000 loss:0.283 acc:0.345 acc_all:0.134\n",
            "800/5000 loss:0.283 acc:0.345 acc_all:0.134\n",
            "810/5000 loss:0.283 acc:0.347 acc_all:0.136\n",
            "820/5000 loss:0.283 acc:0.349 acc_all:0.136\n",
            "830/5000 loss:0.283 acc:0.349 acc_all:0.136\n",
            "840/5000 loss:0.282 acc:0.349 acc_all:0.136\n",
            "850/5000 loss:0.282 acc:0.350 acc_all:0.138\n",
            "860/5000 loss:0.282 acc:0.351 acc_all:0.138\n",
            "870/5000 loss:0.282 acc:0.351 acc_all:0.138\n",
            "880/5000 loss:0.282 acc:0.350 acc_all:0.136\n",
            "890/5000 loss:0.282 acc:0.349 acc_all:0.134\n",
            "900/5000 loss:0.281 acc:0.350 acc_all:0.134\n",
            "910/5000 loss:0.281 acc:0.350 acc_all:0.134\n",
            "920/5000 loss:0.281 acc:0.349 acc_all:0.131\n",
            "930/5000 loss:0.281 acc:0.349 acc_all:0.131\n",
            "940/5000 loss:0.281 acc:0.349 acc_all:0.131\n",
            "950/5000 loss:0.281 acc:0.349 acc_all:0.131\n",
            "960/5000 loss:0.281 acc:0.350 acc_all:0.131\n",
            "970/5000 loss:0.280 acc:0.351 acc_all:0.131\n",
            "980/5000 loss:0.280 acc:0.351 acc_all:0.131\n",
            "990/5000 loss:0.280 acc:0.352 acc_all:0.134\n",
            "1000/5000 loss:0.280 acc:0.352 acc_all:0.134\n",
            "1010/5000 loss:0.280 acc:0.352 acc_all:0.134\n",
            "1020/5000 loss:0.280 acc:0.353 acc_all:0.134\n",
            "1030/5000 loss:0.279 acc:0.354 acc_all:0.136\n",
            "1040/5000 loss:0.279 acc:0.355 acc_all:0.136\n",
            "1050/5000 loss:0.279 acc:0.355 acc_all:0.136\n",
            "1060/5000 loss:0.279 acc:0.355 acc_all:0.136\n",
            "1070/5000 loss:0.279 acc:0.356 acc_all:0.138\n",
            "1080/5000 loss:0.279 acc:0.357 acc_all:0.140\n",
            "1090/5000 loss:0.278 acc:0.357 acc_all:0.140\n",
            "1100/5000 loss:0.278 acc:0.357 acc_all:0.140\n",
            "1110/5000 loss:0.278 acc:0.357 acc_all:0.138\n",
            "1120/5000 loss:0.278 acc:0.357 acc_all:0.138\n",
            "1130/5000 loss:0.278 acc:0.357 acc_all:0.138\n",
            "1140/5000 loss:0.278 acc:0.357 acc_all:0.138\n",
            "1150/5000 loss:0.277 acc:0.359 acc_all:0.138\n",
            "1160/5000 loss:0.277 acc:0.359 acc_all:0.138\n",
            "1170/5000 loss:0.277 acc:0.360 acc_all:0.138\n",
            "1180/5000 loss:0.277 acc:0.361 acc_all:0.138\n",
            "1190/5000 loss:0.277 acc:0.361 acc_all:0.138\n",
            "1200/5000 loss:0.277 acc:0.361 acc_all:0.138\n",
            "1210/5000 loss:0.276 acc:0.362 acc_all:0.138\n",
            "1220/5000 loss:0.276 acc:0.360 acc_all:0.140\n",
            "1230/5000 loss:0.276 acc:0.361 acc_all:0.140\n",
            "1240/5000 loss:0.276 acc:0.363 acc_all:0.140\n",
            "1250/5000 loss:0.276 acc:0.364 acc_all:0.143\n",
            "1260/5000 loss:0.276 acc:0.365 acc_all:0.143\n",
            "1270/5000 loss:0.275 acc:0.365 acc_all:0.143\n",
            "1280/5000 loss:0.275 acc:0.365 acc_all:0.143\n",
            "1290/5000 loss:0.275 acc:0.365 acc_all:0.143\n",
            "1300/5000 loss:0.275 acc:0.365 acc_all:0.143\n",
            "1310/5000 loss:0.275 acc:0.366 acc_all:0.145\n",
            "1320/5000 loss:0.275 acc:0.367 acc_all:0.145\n",
            "1330/5000 loss:0.274 acc:0.370 acc_all:0.149\n",
            "1340/5000 loss:0.274 acc:0.372 acc_all:0.154\n",
            "1350/5000 loss:0.274 acc:0.372 acc_all:0.154\n",
            "1360/5000 loss:0.274 acc:0.373 acc_all:0.154\n",
            "1370/5000 loss:0.274 acc:0.373 acc_all:0.154\n",
            "1380/5000 loss:0.274 acc:0.373 acc_all:0.154\n",
            "1390/5000 loss:0.273 acc:0.373 acc_all:0.154\n",
            "1400/5000 loss:0.273 acc:0.375 acc_all:0.154\n",
            "1410/5000 loss:0.273 acc:0.375 acc_all:0.154\n",
            "1420/5000 loss:0.273 acc:0.376 acc_all:0.154\n",
            "1430/5000 loss:0.273 acc:0.379 acc_all:0.158\n",
            "1440/5000 loss:0.273 acc:0.380 acc_all:0.158\n",
            "1450/5000 loss:0.272 acc:0.380 acc_all:0.158\n",
            "1460/5000 loss:0.272 acc:0.382 acc_all:0.158\n",
            "1470/5000 loss:0.272 acc:0.384 acc_all:0.160\n",
            "1480/5000 loss:0.272 acc:0.384 acc_all:0.160\n",
            "1490/5000 loss:0.272 acc:0.386 acc_all:0.165\n",
            "1500/5000 loss:0.271 acc:0.388 acc_all:0.165\n",
            "1510/5000 loss:0.271 acc:0.389 acc_all:0.165\n",
            "1520/5000 loss:0.271 acc:0.388 acc_all:0.165\n",
            "1530/5000 loss:0.271 acc:0.389 acc_all:0.165\n",
            "1540/5000 loss:0.271 acc:0.390 acc_all:0.165\n",
            "1550/5000 loss:0.271 acc:0.390 acc_all:0.165\n",
            "1560/5000 loss:0.270 acc:0.391 acc_all:0.165\n",
            "1570/5000 loss:0.270 acc:0.392 acc_all:0.167\n",
            "1580/5000 loss:0.270 acc:0.395 acc_all:0.169\n",
            "1590/5000 loss:0.270 acc:0.398 acc_all:0.169\n",
            "1600/5000 loss:0.270 acc:0.399 acc_all:0.169\n",
            "1610/5000 loss:0.270 acc:0.401 acc_all:0.171\n",
            "1620/5000 loss:0.269 acc:0.401 acc_all:0.174\n",
            "1630/5000 loss:0.269 acc:0.401 acc_all:0.174\n",
            "1640/5000 loss:0.269 acc:0.401 acc_all:0.174\n",
            "1650/5000 loss:0.269 acc:0.399 acc_all:0.174\n",
            "1660/5000 loss:0.269 acc:0.400 acc_all:0.174\n",
            "1670/5000 loss:0.269 acc:0.401 acc_all:0.174\n",
            "1680/5000 loss:0.268 acc:0.402 acc_all:0.174\n",
            "1690/5000 loss:0.268 acc:0.403 acc_all:0.176\n",
            "1700/5000 loss:0.268 acc:0.403 acc_all:0.176\n",
            "1710/5000 loss:0.268 acc:0.404 acc_all:0.176\n",
            "1720/5000 loss:0.268 acc:0.405 acc_all:0.178\n",
            "1730/5000 loss:0.267 acc:0.405 acc_all:0.178\n",
            "1740/5000 loss:0.267 acc:0.405 acc_all:0.178\n",
            "1750/5000 loss:0.267 acc:0.409 acc_all:0.180\n",
            "1760/5000 loss:0.267 acc:0.409 acc_all:0.180\n",
            "1770/5000 loss:0.267 acc:0.409 acc_all:0.180\n",
            "1780/5000 loss:0.267 acc:0.409 acc_all:0.180\n",
            "1790/5000 loss:0.266 acc:0.409 acc_all:0.180\n",
            "1800/5000 loss:0.266 acc:0.409 acc_all:0.180\n",
            "1810/5000 loss:0.266 acc:0.409 acc_all:0.180\n",
            "1820/5000 loss:0.266 acc:0.409 acc_all:0.180\n",
            "1830/5000 loss:0.266 acc:0.410 acc_all:0.180\n",
            "1840/5000 loss:0.265 acc:0.410 acc_all:0.180\n",
            "1850/5000 loss:0.265 acc:0.410 acc_all:0.180\n",
            "1860/5000 loss:0.265 acc:0.410 acc_all:0.180\n",
            "1870/5000 loss:0.265 acc:0.409 acc_all:0.180\n",
            "1880/5000 loss:0.265 acc:0.409 acc_all:0.180\n",
            "1890/5000 loss:0.265 acc:0.409 acc_all:0.180\n",
            "1900/5000 loss:0.264 acc:0.410 acc_all:0.180\n",
            "1910/5000 loss:0.264 acc:0.411 acc_all:0.183\n",
            "1920/5000 loss:0.264 acc:0.412 acc_all:0.183\n",
            "1930/5000 loss:0.264 acc:0.414 acc_all:0.185\n",
            "1940/5000 loss:0.264 acc:0.415 acc_all:0.185\n",
            "1950/5000 loss:0.263 acc:0.415 acc_all:0.185\n",
            "1960/5000 loss:0.263 acc:0.416 acc_all:0.185\n",
            "1970/5000 loss:0.263 acc:0.416 acc_all:0.185\n",
            "1980/5000 loss:0.263 acc:0.416 acc_all:0.185\n",
            "1990/5000 loss:0.263 acc:0.418 acc_all:0.187\n",
            "2000/5000 loss:0.262 acc:0.416 acc_all:0.187\n",
            "2010/5000 loss:0.262 acc:0.419 acc_all:0.189\n",
            "2020/5000 loss:0.262 acc:0.419 acc_all:0.189\n",
            "2030/5000 loss:0.262 acc:0.419 acc_all:0.189\n",
            "2040/5000 loss:0.262 acc:0.421 acc_all:0.194\n",
            "2050/5000 loss:0.261 acc:0.421 acc_all:0.194\n",
            "2060/5000 loss:0.261 acc:0.421 acc_all:0.194\n",
            "2070/5000 loss:0.261 acc:0.422 acc_all:0.194\n",
            "2080/5000 loss:0.261 acc:0.423 acc_all:0.196\n",
            "2090/5000 loss:0.261 acc:0.424 acc_all:0.198\n",
            "2100/5000 loss:0.261 acc:0.425 acc_all:0.200\n",
            "2110/5000 loss:0.260 acc:0.425 acc_all:0.200\n",
            "2120/5000 loss:0.260 acc:0.425 acc_all:0.200\n",
            "2130/5000 loss:0.260 acc:0.428 acc_all:0.200\n",
            "2140/5000 loss:0.260 acc:0.428 acc_all:0.200\n",
            "2150/5000 loss:0.260 acc:0.428 acc_all:0.203\n",
            "2160/5000 loss:0.259 acc:0.428 acc_all:0.203\n",
            "2170/5000 loss:0.259 acc:0.428 acc_all:0.203\n",
            "2180/5000 loss:0.259 acc:0.427 acc_all:0.203\n",
            "2190/5000 loss:0.259 acc:0.428 acc_all:0.203\n",
            "2200/5000 loss:0.259 acc:0.429 acc_all:0.205\n",
            "2210/5000 loss:0.258 acc:0.430 acc_all:0.207\n",
            "2220/5000 loss:0.258 acc:0.431 acc_all:0.209\n",
            "2230/5000 loss:0.258 acc:0.431 acc_all:0.209\n",
            "2240/5000 loss:0.258 acc:0.432 acc_all:0.212\n",
            "2250/5000 loss:0.258 acc:0.432 acc_all:0.212\n",
            "2260/5000 loss:0.257 acc:0.432 acc_all:0.212\n",
            "2270/5000 loss:0.257 acc:0.432 acc_all:0.212\n",
            "2280/5000 loss:0.257 acc:0.433 acc_all:0.214\n",
            "2290/5000 loss:0.257 acc:0.437 acc_all:0.218\n",
            "2300/5000 loss:0.257 acc:0.437 acc_all:0.218\n",
            "2310/5000 loss:0.256 acc:0.438 acc_all:0.220\n",
            "2320/5000 loss:0.256 acc:0.439 acc_all:0.220\n",
            "2330/5000 loss:0.256 acc:0.440 acc_all:0.223\n",
            "2340/5000 loss:0.256 acc:0.441 acc_all:0.225\n",
            "2350/5000 loss:0.256 acc:0.441 acc_all:0.225\n",
            "2360/5000 loss:0.255 acc:0.441 acc_all:0.225\n",
            "2370/5000 loss:0.255 acc:0.442 acc_all:0.225\n",
            "2380/5000 loss:0.255 acc:0.443 acc_all:0.227\n",
            "2390/5000 loss:0.255 acc:0.444 acc_all:0.227\n",
            "2400/5000 loss:0.255 acc:0.444 acc_all:0.227\n",
            "2410/5000 loss:0.254 acc:0.444 acc_all:0.227\n",
            "2420/5000 loss:0.254 acc:0.445 acc_all:0.229\n",
            "2430/5000 loss:0.254 acc:0.445 acc_all:0.229\n",
            "2440/5000 loss:0.254 acc:0.445 acc_all:0.232\n",
            "2450/5000 loss:0.254 acc:0.445 acc_all:0.232\n",
            "2460/5000 loss:0.253 acc:0.445 acc_all:0.232\n",
            "2470/5000 loss:0.253 acc:0.445 acc_all:0.232\n",
            "2480/5000 loss:0.253 acc:0.444 acc_all:0.232\n",
            "2490/5000 loss:0.253 acc:0.445 acc_all:0.232\n",
            "2500/5000 loss:0.253 acc:0.445 acc_all:0.232\n",
            "2510/5000 loss:0.252 acc:0.445 acc_all:0.232\n",
            "2520/5000 loss:0.252 acc:0.445 acc_all:0.232\n",
            "2530/5000 loss:0.252 acc:0.448 acc_all:0.232\n",
            "2540/5000 loss:0.252 acc:0.448 acc_all:0.232\n",
            "2550/5000 loss:0.252 acc:0.448 acc_all:0.229\n",
            "2560/5000 loss:0.251 acc:0.448 acc_all:0.229\n",
            "2570/5000 loss:0.251 acc:0.448 acc_all:0.229\n",
            "2580/5000 loss:0.251 acc:0.448 acc_all:0.229\n",
            "2590/5000 loss:0.251 acc:0.450 acc_all:0.232\n",
            "2600/5000 loss:0.251 acc:0.450 acc_all:0.232\n",
            "2610/5000 loss:0.250 acc:0.451 acc_all:0.232\n",
            "2620/5000 loss:0.250 acc:0.451 acc_all:0.234\n",
            "2630/5000 loss:0.250 acc:0.450 acc_all:0.234\n",
            "2640/5000 loss:0.250 acc:0.453 acc_all:0.236\n",
            "2650/5000 loss:0.250 acc:0.453 acc_all:0.236\n",
            "2660/5000 loss:0.249 acc:0.453 acc_all:0.236\n",
            "2670/5000 loss:0.249 acc:0.453 acc_all:0.236\n",
            "2680/5000 loss:0.249 acc:0.453 acc_all:0.236\n",
            "2690/5000 loss:0.249 acc:0.453 acc_all:0.236\n",
            "2700/5000 loss:0.249 acc:0.453 acc_all:0.236\n",
            "2710/5000 loss:0.248 acc:0.453 acc_all:0.236\n",
            "2720/5000 loss:0.248 acc:0.454 acc_all:0.236\n",
            "2730/5000 loss:0.248 acc:0.455 acc_all:0.236\n",
            "2740/5000 loss:0.248 acc:0.455 acc_all:0.236\n",
            "2750/5000 loss:0.248 acc:0.458 acc_all:0.238\n",
            "2760/5000 loss:0.247 acc:0.459 acc_all:0.238\n",
            "2770/5000 loss:0.247 acc:0.459 acc_all:0.238\n",
            "2780/5000 loss:0.247 acc:0.459 acc_all:0.238\n",
            "2790/5000 loss:0.247 acc:0.461 acc_all:0.238\n",
            "2800/5000 loss:0.246 acc:0.460 acc_all:0.238\n",
            "2810/5000 loss:0.246 acc:0.462 acc_all:0.241\n",
            "2820/5000 loss:0.246 acc:0.462 acc_all:0.241\n",
            "2830/5000 loss:0.246 acc:0.463 acc_all:0.241\n",
            "2840/5000 loss:0.246 acc:0.463 acc_all:0.241\n",
            "2850/5000 loss:0.245 acc:0.463 acc_all:0.241\n",
            "2860/5000 loss:0.245 acc:0.463 acc_all:0.241\n",
            "2870/5000 loss:0.245 acc:0.464 acc_all:0.241\n",
            "2880/5000 loss:0.245 acc:0.465 acc_all:0.241\n",
            "2890/5000 loss:0.245 acc:0.465 acc_all:0.241\n",
            "2900/5000 loss:0.244 acc:0.465 acc_all:0.241\n",
            "2910/5000 loss:0.244 acc:0.465 acc_all:0.241\n",
            "2920/5000 loss:0.244 acc:0.467 acc_all:0.243\n",
            "2930/5000 loss:0.244 acc:0.465 acc_all:0.241\n",
            "2940/5000 loss:0.244 acc:0.470 acc_all:0.247\n",
            "2950/5000 loss:0.243 acc:0.471 acc_all:0.247\n",
            "2960/5000 loss:0.243 acc:0.471 acc_all:0.247\n",
            "2970/5000 loss:0.243 acc:0.472 acc_all:0.249\n",
            "2980/5000 loss:0.243 acc:0.472 acc_all:0.249\n",
            "2990/5000 loss:0.243 acc:0.473 acc_all:0.249\n",
            "3000/5000 loss:0.242 acc:0.473 acc_all:0.249\n",
            "3010/5000 loss:0.242 acc:0.473 acc_all:0.249\n",
            "3020/5000 loss:0.242 acc:0.474 acc_all:0.252\n",
            "3030/5000 loss:0.242 acc:0.478 acc_all:0.256\n",
            "3040/5000 loss:0.241 acc:0.478 acc_all:0.256\n",
            "3050/5000 loss:0.241 acc:0.478 acc_all:0.256\n",
            "3060/5000 loss:0.241 acc:0.479 acc_all:0.256\n",
            "3070/5000 loss:0.241 acc:0.479 acc_all:0.256\n",
            "3080/5000 loss:0.241 acc:0.482 acc_all:0.256\n",
            "3090/5000 loss:0.240 acc:0.482 acc_all:0.256\n",
            "3100/5000 loss:0.240 acc:0.482 acc_all:0.256\n",
            "3110/5000 loss:0.240 acc:0.483 acc_all:0.256\n",
            "3120/5000 loss:0.240 acc:0.483 acc_all:0.256\n",
            "3130/5000 loss:0.240 acc:0.483 acc_all:0.256\n",
            "3140/5000 loss:0.239 acc:0.483 acc_all:0.256\n",
            "3150/5000 loss:0.239 acc:0.483 acc_all:0.256\n",
            "3160/5000 loss:0.239 acc:0.484 acc_all:0.258\n",
            "3170/5000 loss:0.239 acc:0.486 acc_all:0.261\n",
            "3180/5000 loss:0.239 acc:0.486 acc_all:0.261\n",
            "3190/5000 loss:0.238 acc:0.487 acc_all:0.263\n",
            "3200/5000 loss:0.238 acc:0.488 acc_all:0.265\n",
            "3210/5000 loss:0.238 acc:0.489 acc_all:0.265\n",
            "3220/5000 loss:0.238 acc:0.490 acc_all:0.265\n",
            "3230/5000 loss:0.237 acc:0.490 acc_all:0.265\n",
            "3240/5000 loss:0.237 acc:0.490 acc_all:0.265\n",
            "3250/5000 loss:0.237 acc:0.491 acc_all:0.265\n",
            "3260/5000 loss:0.237 acc:0.491 acc_all:0.265\n",
            "3270/5000 loss:0.237 acc:0.490 acc_all:0.263\n",
            "3280/5000 loss:0.236 acc:0.491 acc_all:0.265\n",
            "3290/5000 loss:0.236 acc:0.491 acc_all:0.265\n",
            "3300/5000 loss:0.236 acc:0.492 acc_all:0.265\n",
            "3310/5000 loss:0.236 acc:0.493 acc_all:0.267\n",
            "3320/5000 loss:0.235 acc:0.493 acc_all:0.267\n",
            "3330/5000 loss:0.235 acc:0.494 acc_all:0.269\n",
            "3340/5000 loss:0.235 acc:0.496 acc_all:0.272\n",
            "3350/5000 loss:0.235 acc:0.496 acc_all:0.272\n",
            "3360/5000 loss:0.235 acc:0.497 acc_all:0.272\n",
            "3370/5000 loss:0.234 acc:0.498 acc_all:0.272\n",
            "3380/5000 loss:0.234 acc:0.498 acc_all:0.272\n",
            "3390/5000 loss:0.234 acc:0.498 acc_all:0.272\n",
            "3400/5000 loss:0.234 acc:0.499 acc_all:0.274\n",
            "3410/5000 loss:0.234 acc:0.499 acc_all:0.274\n",
            "3420/5000 loss:0.233 acc:0.499 acc_all:0.274\n",
            "3430/5000 loss:0.233 acc:0.499 acc_all:0.274\n",
            "3440/5000 loss:0.233 acc:0.499 acc_all:0.274\n",
            "3450/5000 loss:0.233 acc:0.500 acc_all:0.276\n",
            "3460/5000 loss:0.232 acc:0.500 acc_all:0.276\n",
            "3470/5000 loss:0.232 acc:0.500 acc_all:0.276\n",
            "3480/5000 loss:0.232 acc:0.501 acc_all:0.276\n",
            "3490/5000 loss:0.232 acc:0.502 acc_all:0.276\n",
            "3500/5000 loss:0.231 acc:0.502 acc_all:0.276\n",
            "3510/5000 loss:0.231 acc:0.502 acc_all:0.276\n",
            "3520/5000 loss:0.231 acc:0.503 acc_all:0.276\n",
            "3530/5000 loss:0.231 acc:0.503 acc_all:0.276\n",
            "3540/5000 loss:0.231 acc:0.503 acc_all:0.276\n",
            "3550/5000 loss:0.230 acc:0.504 acc_all:0.276\n",
            "3560/5000 loss:0.230 acc:0.507 acc_all:0.276\n",
            "3570/5000 loss:0.230 acc:0.508 acc_all:0.278\n",
            "3580/5000 loss:0.230 acc:0.508 acc_all:0.278\n",
            "3590/5000 loss:0.229 acc:0.508 acc_all:0.278\n",
            "3600/5000 loss:0.229 acc:0.509 acc_all:0.278\n",
            "3610/5000 loss:0.229 acc:0.509 acc_all:0.278\n",
            "3620/5000 loss:0.229 acc:0.509 acc_all:0.278\n",
            "3630/5000 loss:0.229 acc:0.511 acc_all:0.281\n",
            "3640/5000 loss:0.228 acc:0.511 acc_all:0.281\n",
            "3650/5000 loss:0.228 acc:0.512 acc_all:0.283\n",
            "3660/5000 loss:0.228 acc:0.512 acc_all:0.283\n",
            "3670/5000 loss:0.228 acc:0.512 acc_all:0.283\n",
            "3680/5000 loss:0.227 acc:0.512 acc_all:0.283\n",
            "3690/5000 loss:0.227 acc:0.513 acc_all:0.283\n",
            "3700/5000 loss:0.227 acc:0.514 acc_all:0.285\n",
            "3710/5000 loss:0.227 acc:0.513 acc_all:0.285\n",
            "3720/5000 loss:0.226 acc:0.514 acc_all:0.287\n",
            "3730/5000 loss:0.226 acc:0.516 acc_all:0.290\n",
            "3740/5000 loss:0.226 acc:0.516 acc_all:0.290\n",
            "3750/5000 loss:0.226 acc:0.517 acc_all:0.290\n",
            "3760/5000 loss:0.226 acc:0.518 acc_all:0.292\n",
            "3770/5000 loss:0.225 acc:0.519 acc_all:0.292\n",
            "3780/5000 loss:0.225 acc:0.520 acc_all:0.294\n",
            "3790/5000 loss:0.225 acc:0.521 acc_all:0.294\n",
            "3800/5000 loss:0.225 acc:0.522 acc_all:0.296\n",
            "3810/5000 loss:0.224 acc:0.522 acc_all:0.296\n",
            "3820/5000 loss:0.224 acc:0.523 acc_all:0.298\n",
            "3830/5000 loss:0.224 acc:0.523 acc_all:0.298\n",
            "3840/5000 loss:0.224 acc:0.524 acc_all:0.301\n",
            "3850/5000 loss:0.223 acc:0.524 acc_all:0.301\n",
            "3860/5000 loss:0.223 acc:0.526 acc_all:0.301\n",
            "3870/5000 loss:0.223 acc:0.527 acc_all:0.303\n",
            "3880/5000 loss:0.223 acc:0.528 acc_all:0.303\n",
            "3890/5000 loss:0.223 acc:0.529 acc_all:0.305\n",
            "3900/5000 loss:0.222 acc:0.529 acc_all:0.305\n",
            "3910/5000 loss:0.222 acc:0.529 acc_all:0.305\n",
            "3920/5000 loss:0.222 acc:0.529 acc_all:0.305\n",
            "3930/5000 loss:0.222 acc:0.529 acc_all:0.305\n",
            "3940/5000 loss:0.221 acc:0.529 acc_all:0.305\n",
            "3950/5000 loss:0.221 acc:0.530 acc_all:0.305\n",
            "3960/5000 loss:0.221 acc:0.530 acc_all:0.305\n",
            "3970/5000 loss:0.221 acc:0.530 acc_all:0.305\n",
            "3980/5000 loss:0.220 acc:0.532 acc_all:0.305\n",
            "3990/5000 loss:0.220 acc:0.532 acc_all:0.305\n",
            "4000/5000 loss:0.220 acc:0.532 acc_all:0.305\n",
            "4010/5000 loss:0.220 acc:0.533 acc_all:0.307\n",
            "4020/5000 loss:0.219 acc:0.535 acc_all:0.310\n",
            "4030/5000 loss:0.219 acc:0.535 acc_all:0.310\n",
            "4040/5000 loss:0.219 acc:0.537 acc_all:0.312\n",
            "4050/5000 loss:0.219 acc:0.537 acc_all:0.312\n",
            "4060/5000 loss:0.219 acc:0.537 acc_all:0.312\n",
            "4070/5000 loss:0.218 acc:0.537 acc_all:0.312\n",
            "4080/5000 loss:0.218 acc:0.538 acc_all:0.312\n",
            "4090/5000 loss:0.218 acc:0.539 acc_all:0.312\n",
            "4100/5000 loss:0.218 acc:0.540 acc_all:0.314\n",
            "4110/5000 loss:0.217 acc:0.540 acc_all:0.314\n",
            "4120/5000 loss:0.217 acc:0.540 acc_all:0.314\n",
            "4130/5000 loss:0.217 acc:0.541 acc_all:0.316\n",
            "4140/5000 loss:0.217 acc:0.541 acc_all:0.316\n",
            "4150/5000 loss:0.216 acc:0.543 acc_all:0.318\n",
            "4160/5000 loss:0.216 acc:0.543 acc_all:0.318\n",
            "4170/5000 loss:0.216 acc:0.545 acc_all:0.321\n",
            "4180/5000 loss:0.216 acc:0.545 acc_all:0.321\n",
            "4190/5000 loss:0.215 acc:0.546 acc_all:0.321\n",
            "4200/5000 loss:0.215 acc:0.547 acc_all:0.323\n",
            "4210/5000 loss:0.215 acc:0.547 acc_all:0.323\n",
            "4220/5000 loss:0.215 acc:0.547 acc_all:0.323\n",
            "4230/5000 loss:0.214 acc:0.548 acc_all:0.325\n",
            "4240/5000 loss:0.214 acc:0.550 acc_all:0.327\n",
            "4250/5000 loss:0.214 acc:0.551 acc_all:0.327\n",
            "4260/5000 loss:0.214 acc:0.551 acc_all:0.327\n",
            "4270/5000 loss:0.213 acc:0.551 acc_all:0.327\n",
            "4280/5000 loss:0.213 acc:0.551 acc_all:0.327\n",
            "4290/5000 loss:0.213 acc:0.553 acc_all:0.330\n",
            "4300/5000 loss:0.213 acc:0.555 acc_all:0.332\n",
            "4310/5000 loss:0.212 acc:0.557 acc_all:0.332\n",
            "4320/5000 loss:0.212 acc:0.558 acc_all:0.332\n",
            "4330/5000 loss:0.212 acc:0.559 acc_all:0.334\n",
            "4340/5000 loss:0.212 acc:0.559 acc_all:0.334\n",
            "4350/5000 loss:0.211 acc:0.559 acc_all:0.334\n",
            "4360/5000 loss:0.211 acc:0.561 acc_all:0.339\n",
            "4370/5000 loss:0.211 acc:0.562 acc_all:0.341\n",
            "4380/5000 loss:0.211 acc:0.566 acc_all:0.343\n",
            "4390/5000 loss:0.210 acc:0.566 acc_all:0.343\n",
            "4400/5000 loss:0.210 acc:0.566 acc_all:0.343\n",
            "4410/5000 loss:0.210 acc:0.567 acc_all:0.343\n",
            "4420/5000 loss:0.210 acc:0.568 acc_all:0.345\n",
            "4430/5000 loss:0.209 acc:0.570 acc_all:0.347\n",
            "4440/5000 loss:0.209 acc:0.570 acc_all:0.347\n",
            "4450/5000 loss:0.209 acc:0.570 acc_all:0.347\n",
            "4460/5000 loss:0.209 acc:0.571 acc_all:0.347\n",
            "4470/5000 loss:0.208 acc:0.571 acc_all:0.347\n",
            "4480/5000 loss:0.208 acc:0.573 acc_all:0.352\n",
            "4490/5000 loss:0.208 acc:0.573 acc_all:0.352\n",
            "4500/5000 loss:0.208 acc:0.572 acc_all:0.352\n",
            "4510/5000 loss:0.207 acc:0.572 acc_all:0.352\n",
            "4520/5000 loss:0.207 acc:0.573 acc_all:0.352\n",
            "4530/5000 loss:0.207 acc:0.575 acc_all:0.354\n",
            "4540/5000 loss:0.207 acc:0.576 acc_all:0.356\n",
            "4550/5000 loss:0.206 acc:0.578 acc_all:0.361\n",
            "4560/5000 loss:0.206 acc:0.579 acc_all:0.361\n",
            "4570/5000 loss:0.206 acc:0.582 acc_all:0.363\n",
            "4580/5000 loss:0.206 acc:0.584 acc_all:0.365\n",
            "4590/5000 loss:0.205 acc:0.585 acc_all:0.367\n",
            "4600/5000 loss:0.205 acc:0.586 acc_all:0.370\n",
            "4610/5000 loss:0.205 acc:0.587 acc_all:0.372\n",
            "4620/5000 loss:0.205 acc:0.588 acc_all:0.372\n",
            "4630/5000 loss:0.204 acc:0.592 acc_all:0.381\n",
            "4640/5000 loss:0.204 acc:0.592 acc_all:0.381\n",
            "4650/5000 loss:0.204 acc:0.594 acc_all:0.381\n",
            "4660/5000 loss:0.204 acc:0.595 acc_all:0.381\n",
            "4670/5000 loss:0.203 acc:0.595 acc_all:0.381\n",
            "4680/5000 loss:0.203 acc:0.595 acc_all:0.381\n",
            "4690/5000 loss:0.203 acc:0.595 acc_all:0.381\n",
            "4700/5000 loss:0.203 acc:0.595 acc_all:0.381\n",
            "4710/5000 loss:0.202 acc:0.595 acc_all:0.381\n",
            "4720/5000 loss:0.202 acc:0.595 acc_all:0.381\n",
            "4730/5000 loss:0.202 acc:0.595 acc_all:0.381\n",
            "4740/5000 loss:0.202 acc:0.595 acc_all:0.381\n",
            "4750/5000 loss:0.201 acc:0.597 acc_all:0.385\n",
            "4760/5000 loss:0.201 acc:0.597 acc_all:0.385\n",
            "4770/5000 loss:0.201 acc:0.597 acc_all:0.385\n",
            "4780/5000 loss:0.200 acc:0.597 acc_all:0.385\n",
            "4790/5000 loss:0.200 acc:0.599 acc_all:0.390\n",
            "4800/5000 loss:0.200 acc:0.600 acc_all:0.392\n",
            "4810/5000 loss:0.200 acc:0.601 acc_all:0.392\n",
            "4820/5000 loss:0.199 acc:0.602 acc_all:0.394\n",
            "4830/5000 loss:0.199 acc:0.602 acc_all:0.394\n",
            "4840/5000 loss:0.199 acc:0.602 acc_all:0.394\n",
            "4850/5000 loss:0.199 acc:0.601 acc_all:0.394\n",
            "4860/5000 loss:0.198 acc:0.601 acc_all:0.394\n",
            "4870/5000 loss:0.198 acc:0.601 acc_all:0.394\n",
            "4880/5000 loss:0.198 acc:0.602 acc_all:0.394\n",
            "4890/5000 loss:0.198 acc:0.604 acc_all:0.396\n",
            "4900/5000 loss:0.197 acc:0.605 acc_all:0.396\n",
            "4910/5000 loss:0.197 acc:0.606 acc_all:0.396\n",
            "4920/5000 loss:0.197 acc:0.611 acc_all:0.399\n",
            "4930/5000 loss:0.197 acc:0.612 acc_all:0.399\n",
            "4940/5000 loss:0.196 acc:0.612 acc_all:0.399\n",
            "4950/5000 loss:0.196 acc:0.612 acc_all:0.399\n",
            "4960/5000 loss:0.196 acc:0.614 acc_all:0.401\n",
            "4970/5000 loss:0.196 acc:0.615 acc_all:0.403\n",
            "4980/5000 loss:0.195 acc:0.615 acc_all:0.401\n",
            "4990/5000 loss:0.195 acc:0.615 acc_all:0.401\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H_FA2_i0GLLh",
        "colab_type": "code",
        "outputId": "36698cec-d382-45e4-b490-b633bc95d447",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# 테스트셋의 성능\n",
        "h = model(x_test)\n",
        "model.get_accuracy(y_test, h)\n",
        "print('개별정확도',model.acc.numpy(),'두자리 모두 맞춘 정확도', model.acc_all.numpy())"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "개별정확도 0.08017817 두자리 모두 맞춘 정확도 0.0066815144\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}